{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f8bc939",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a776b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If needed, install the following packages:\n",
    "\n",
    "# !pip install azure-ai-documentintelligence==1.0.0b1\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install tensorflow\n",
    "# !pip install sklearn\n",
    "# !pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87da61b2-5535-4b25-8bd1-394a71d9de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.core.credentials import AzureKeyCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ab7493-5d6a-40b9-a4d5-e02e4e4853aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-17 21:45:27.436717: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-17 21:45:28.662942: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-17 21:45:29.772070: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737150330.600415   99608 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737150330.837609   99608 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-17 21:45:33.122077: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import io\n",
    "import copy\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics.pairwise import euclidean_distances as L2, cosine_similarity as cs\n",
    "from collections import defaultdict, Counter\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d71c4-795e-4666-ba36-93dc65450812",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92243b42-697a-4184-82cb-408ddf11dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'model.keras'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a7da0e",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae310352",
   "metadata": {},
   "source": [
    "Use the model parameters defined in training to configure the model settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27fb729c-6cc3-4e86-be46-3250c500584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "MODEL_ARCHITECTURE = tf.keras.applications.ResNet50V2\n",
    "LAST_LAYER_SIZE = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fbaadc6-69ab-4f96-b115-baf4f4e7c68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-17 21:45:44.677255: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "embeddings_base_model = MODEL_ARCHITECTURE(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    pooling='avg',\n",
    ")\n",
    "embeddings_model = models.Sequential([\n",
    "        embeddings_base_model,  \n",
    "        layers.Dense(LAST_LAYER_SIZE, activation=None), \n",
    "        layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) \n",
    "    ])\n",
    "image_input1 = Input(shape=(IMG_SIZE,IMG_SIZE,3),name='Image1')\n",
    "image_input2 = Input(shape=(IMG_SIZE,IMG_SIZE,3),name='Image2')\n",
    "image_input3 = Input(shape=(IMG_SIZE,IMG_SIZE,3),name='Image3')\n",
    "\n",
    "anchor = embeddings_model(image_input1)\n",
    "positive = embeddings_model(image_input2)\n",
    "negative = embeddings_model(image_input3)\n",
    "\n",
    "siamese_network = Model(inputs=[image_input1,image_input2,image_input3], outputs=[anchor,positive,negative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00874ea0-77b7-4d74-beed-a9acfcf91413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "siamese_network.load_weights(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1fdb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embeddings_model = siamese_network.layers[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45fb040-1fe2-42d1-a002-dcfe5accd6e3",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd5c7ae",
   "metadata": {},
   "source": [
    "The images need to be preprocessed according to the preprocessing of the training set.\n",
    "<br>\n",
    "I order to do that, the OCR will be extracted and some transformations will be applied on the images.\n",
    "<br>\n",
    "The images need to be all in one folder, which path needs to be defined in DOCS_PATH.\n",
    "<br>\n",
    "The extracted OCR in json files will be stored in IMAGES_OCR_PATH.\n",
    "<br>\n",
    "The preprocessed images will be stored in DOCS_PREPROCESSED_PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f96dae3-1f0b-4e30-ae9c-c17afc1d2e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS_PATH = '/home/dut-ftp-user/Documents/miguel/JupyterWorkspace/Similarity Classifier Siamese Network/EOB 2024-10-15/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca36d1e3-177b-457b-a675-d16e31fd212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS_PREPROCESSED_PATH = '/home/dut-ftp-user/Documents/miguel/JupyterWorkspace/Similarity Classifier Siamese Network/EOB 2024-10-15/preprocessed_images/'\n",
    "if not os.path.exists(DOCS_PREPROCESSED_PATH):\n",
    "    os.mkdir(DOCS_PREPROCESSED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77249634-4680-4e81-b9c0-ed1ca45ab333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR extraction configuration\n",
    "\n",
    "IMAGES_OCR_PATH = '/home/dut-ftp-user/Documents/miguel/JupyterWorkspace/Similarity Classifier Siamese Network/EOB 2024-10-15/images_ocr/'\n",
    "if not os.path.exists(IMAGES_OCR_PATH):\n",
    "    os.mkdir(IMAGES_OCR_PATH)\n",
    "\n",
    "AZURE_DI_ENDPOINT = 'https://doc-intelligence-smartops-t102.cognitiveservices.azure.com/'\n",
    "AZURE_DI_SUBSCRIPTION_KEY = '7319cf168ac1453b8185c4c9cbf49f6d'\n",
    "AZURE_DI_DEFAULT_CONFIG = {} \n",
    "AZURE_DI_CONFIG_READING_ORDER = 'readingOrder'\n",
    "AZURE_DI_MODEL_ID = 'prebuilt-read'\n",
    "AZURE_DI_CONTENT_TYPE = 'application/octet-stream'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b9dad-829f-4a0e-98a5-c4dd0b57def0",
   "metadata": {},
   "source": [
    "## OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6996c7ce-68ec-42a6-ad14-20d566332010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_azure_di_ocr(client, image: np.ndarray):\n",
    "    _, im_buf_arr = cv2.imencode('.jpg', image)\n",
    "    img = io.BytesIO(im_buf_arr)\n",
    "    config = {key: value for key, value in AZURE_DI_DEFAULT_CONFIG.items() if (key != AZURE_DI_CONFIG_READING_ORDER)}\n",
    "    poller = client.begin_analyze_document(\n",
    "        model_id=AZURE_DI_MODEL_ID,\n",
    "        analyze_request=img,\n",
    "        content_type=AZURE_DI_CONTENT_TYPE,\n",
    "        **config\n",
    "    )\n",
    "    return poller.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70d3b513-7b8f-4fa8-bdbd-4d88d8e619fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_box(bb_list):\n",
    "    bb_x = bb_list[::2]\n",
    "    bb_y = bb_list[1::2]\n",
    "    return [int(min(bb_x)), int(min(bb_y)), int(max(bb_x)), int(max(bb_y))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a6a22e3-04a0-4f44-ba19-c4c4f9de658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_words(image_path):\n",
    "    img = load_img(image_path)\n",
    "    img = img_to_array(img)\n",
    "    img_ocr = do_azure_di_ocr(azure_di_client, img)\n",
    "    img_words = []\n",
    "    for word in img_ocr['pages'][0]['words']:\n",
    "        img_words.append({'bbox': get_bounding_box(bb_list=word.polygon),\n",
    "                          'text': word.content})\n",
    "    return img_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e8d66e-b4c0-43cd-b028-2b133a707bdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract and save OCR\n",
    "\n",
    "azure_di_client = DocumentIntelligenceClient(endpoint=AZURE_DI_ENDPOINT, credential=AzureKeyCredential(AZURE_DI_SUBSCRIPTION_KEY))\n",
    "for dirpath, dirnames, filenames in os.walk(DOCS_PATH):\n",
    "    for i, image_name in enumerate(filenames):\n",
    "        if image_name.replace('.jpg', '.json') not in os.listdir(IMAGES_OCR_PATH):\n",
    "            print(f'{i+1}/{len(os.listdir(DOCS_PATH))}')\n",
    "            img_words = get_image_words(os.path.join(dirpath, image_name))\n",
    "            with open(os.path.join(IMAGES_OCR_PATH, image_name.replace('.jpg', '.json')), 'w') as f:\n",
    "                json.dump(img_words, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd33b55c-6e15-4f78-8a55-b4c68370c06b",
   "metadata": {},
   "source": [
    "## Image Alterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92a0811a-9d50-44ec-9f0c-29b4bdc78bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_2_images_from_array(img1, img2, text_img1='Image 1', text_img2='Image 2'):\n",
    "    f, axarr = plt.subplots(1,2,figsize=(20, 8))\n",
    "    axarr[0].imshow(img1)\n",
    "    axarr[0].title.set_text(text_img1)\n",
    "    # axarr[0].axis('off')\n",
    "    axarr[1].imshow(img2)\n",
    "    axarr[1].title.set_text(text_img2)\n",
    "    # axarr[1].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b112232c-3ef8-4937-b432-786d86649893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_3_images_from_array(img1, img2, img3, \n",
    "                              text_img1='Image 1', \n",
    "                              text_img2='Image 2', \n",
    "                              text_img3='Image 3'):\n",
    "    f, axarr = plt.subplots(1, 3, figsize=(30, 10))\n",
    "    axarr[0].imshow(img1)\n",
    "    axarr[0].title.set_text(text_img1)\n",
    "    axarr[1].imshow(img2)\n",
    "    axarr[1].title.set_text(text_img2)\n",
    "    axarr[2].imshow(img3)\n",
    "    axarr[2].title.set_text(text_img3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "47f22259-e96b-4876-9ddf-c89692390a75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T16:21:43.488082Z",
     "iopub.status.busy": "2025-01-22T16:21:43.487553Z",
     "iopub.status.idle": "2025-01-22T16:21:43.495891Z",
     "shell.execute_reply": "2025-01-22T16:21:43.494397Z",
     "shell.execute_reply.started": "2025-01-22T16:21:43.488046Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_with_white_padding(img):\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    # Calculate padding\n",
    "    if height > width:\n",
    "        pad_width = (height - width) // 2\n",
    "        pad_height = 0\n",
    "        paddings = [[0, 0], [pad_width, pad_width], [0, 0]]\n",
    "    elif width > height:\n",
    "        pad_height = (width - height)\n",
    "        pad_width = 0\n",
    "        paddings = [[0, pad_height], [0, 0], [0, 0]]\n",
    "    else:  \n",
    "        return img\n",
    "    # Pad the image with white pixels using constant value 255\n",
    "    padded_img = tf.pad(img, paddings, constant_values=255)\n",
    "    \n",
    "    return padded_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba63d09-c3a8-4dcf-aab3-252f64dc91c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_max_coords_from_ocr(image, image_ocr):\n",
    "    x_min, y_min = image.shape[1], image.shape[0]\n",
    "    x_max, y_max = 0, 0\n",
    "    for word in image_ocr:\n",
    "        x_min = min(word['bbox'][0], x_min)\n",
    "        y_min = min(word['bbox'][1], y_min)\n",
    "        x_max = max(word['bbox'][2], x_max)\n",
    "        y_max = max(word['bbox'][3], y_max)\n",
    "    return x_min, y_min, x_max, y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4062eb39-2056-4438-9b81-d6d5a9dc5a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T14:51:42.924074Z",
     "iopub.status.busy": "2025-01-22T14:51:42.923721Z",
     "iopub.status.idle": "2025-01-22T14:51:42.946125Z",
     "shell.execute_reply": "2025-01-22T14:51:42.945069Z",
     "shell.execute_reply.started": "2025-01-22T14:51:42.924048Z"
    }
   },
   "outputs": [],
   "source": [
    "def crop_white_border(image, image_ocr):\n",
    "    min_contour_area = (image.shape[0] * image.shape[1]) / 2000\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Convert the image to grayscale\n",
    "    _, thresh = cv2.threshold(gray, 245, 255, cv2.THRESH_BINARY_INV) # Threshold the image to separate foreground and background\n",
    "    thresh = thresh.astype(np.uint8) # Ensure the thresholded image is 8-bit unsigned integer\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # Find contours of non-white regions\n",
    "    # Find the bounding box of the combined region\n",
    "    x_min, y_min, x_max, y_max = get_img_max_coords_from_ocr(image, image_ocr)\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > min_contour_area:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            # cv2.rectangle(image, (x, y), (x+w, y+h), color=(0,0,0), thickness=5)\n",
    "            x_min = min(x, x_min)\n",
    "            y_min = min(y, y_min)\n",
    "            x_max = max(x + w, x_max)\n",
    "            y_max = max(y + h, y_max)\n",
    "    # Crop the image based on the combined bounding box\n",
    "    cropped_image = image[y_min:y_max, x_min:x_max] \n",
    "\n",
    "    # Move cropped area to the middle of the image\n",
    "    original_height, original_width = image.shape[:2]\n",
    "    cropped_height, cropped_width = cropped_image.shape[:2]\n",
    "    padded_image = np.ones((original_height, original_width, image.shape[2]), dtype=image.dtype) * 255\n",
    "    horizontal_offset = (original_width - cropped_width) // 2\n",
    "    padded_image[:cropped_height, horizontal_offset:horizontal_offset + cropped_width] = cropped_image\n",
    "    \n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "46ed8918-8d1d-4fe3-9ed4-88cae22a348b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T16:10:40.264073Z",
     "iopub.status.busy": "2025-01-22T16:10:40.263625Z",
     "iopub.status.idle": "2025-01-22T16:10:40.272141Z",
     "shell.execute_reply": "2025-01-22T16:10:40.270535Z",
     "shell.execute_reply.started": "2025-01-22T16:10:40.264036Z"
    }
   },
   "outputs": [],
   "source": [
    "def thicken_borders(image, color=(0, 0, 0), dilate_iterations=2, canny_threshold1=75, canny_threshold2=150):\n",
    "    image = image.numpy().astype(np.uint8)  # Convert to uint8\n",
    "    thickness = max(int(round(((image.shape[0] + image.shape[1]) / 2) / 400, 0)), 0)\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    # Detect edges using Canny\n",
    "    edges = cv2.Canny(gray, canny_threshold1, canny_threshold2, L2gradient=True)\n",
    "    edge_mask = edges > 0\n",
    "    # Dilate the edges to thicken them\n",
    "    kernel = np.ones((thickness, thickness), np.uint8)\n",
    "    thickened_edges = cv2.dilate(edges, kernel, iterations=dilate_iterations)\n",
    "    # Create a mask for the thickened edges\n",
    "    thicken_edge_mask = thickened_edges > 0\n",
    "    # Create a copy of the original image to modify\n",
    "    result = image.copy()\n",
    "    # Overlay the thickened borders in the specified color\n",
    "    result[thicken_edge_mask] = color        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "41df4b36-ced0-4c2d-93f3-2f29de78c540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T16:10:40.451552Z",
     "iopub.status.busy": "2025-01-22T16:10:40.451136Z",
     "iopub.status.idle": "2025-01-22T16:10:40.458747Z",
     "shell.execute_reply": "2025-01-22T16:10:40.457333Z",
     "shell.execute_reply.started": "2025-01-22T16:10:40.451519Z"
    }
   },
   "outputs": [],
   "source": [
    "def highlight_word(img, word, color):\n",
    "    pt1 = (word['bbox'][0], word['bbox'][1])\n",
    "    pt2 = (word['bbox'][2], word['bbox'][3])\n",
    "    cv2.rectangle(img, pt1, pt2, color, thickness=-1)\n",
    "\n",
    "def highlight_text(img, img_ocr):\n",
    "    for word in img_ocr:\n",
    "        if re.findall('^[\\$€₹]*[0-9,\\-]+\\.*[0-9]+[\\$€₹]*$', word['text']): # Highlight numbers\n",
    "            highlight_word(img, word, color=(255, 0, 0))\n",
    "        elif re.findall('[0-9]{1,2}[/-][0-9]{1,2}[/-][0-9]{2,4}', word['text']): # Highlight dates\n",
    "            highlight_word(img, word, color=(0, 255, 0))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ee4ffd2d-e5b1-45e9-9223-222b348843a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T16:10:40.632536Z",
     "iopub.status.busy": "2025-01-22T16:10:40.632129Z",
     "iopub.status.idle": "2025-01-22T16:10:40.638498Z",
     "shell.execute_reply": "2025-01-22T16:10:40.636977Z",
     "shell.execute_reply.started": "2025-01-22T16:10:40.632508Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_text_size(img_ocr):\n",
    "    words_height = np.array([word['bbox'][3] - word['bbox'][1] for word in img_ocr])\n",
    "    return numpy.median(words_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a8b27254-db1d-4c57-9944-545a57e18656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T16:10:40.810525Z",
     "iopub.status.busy": "2025-01-22T16:10:40.810091Z",
     "iopub.status.idle": "2025-01-22T16:10:40.815927Z",
     "shell.execute_reply": "2025-01-22T16:10:40.814683Z",
     "shell.execute_reply.started": "2025-01-22T16:10:40.810492Z"
    }
   },
   "outputs": [],
   "source": [
    "def doc_preprocessing(img, img_ocr):\n",
    "    img = highlight_text(img, img_ocr)\n",
    "    img = crop_white_border(img, img_ocr)\n",
    "    img = preprocess_with_white_padding(img) # add white padding to keep proportions\n",
    "    img = thicken_borders(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c8016838-2923-4870-86f6-e29b26eaff59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T16:10:41.009463Z",
     "iopub.status.busy": "2025-01-22T16:10:41.009020Z",
     "iopub.status.idle": "2025-01-22T16:10:41.015280Z",
     "shell.execute_reply": "2025-01-22T16:10:41.013859Z",
     "shell.execute_reply.started": "2025-01-22T16:10:41.009430Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, img_ocr_path):\n",
    "    img = load_img(image_path)\n",
    "    img = img_to_array(img)\n",
    "    with open(img_ocr_path) as f:\n",
    "        img_ocr = json.load(f)\n",
    "    img_pp = doc_preprocessing(img, img_ocr)\n",
    "    return img_pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ed462b-868b-4945-ad45-50bd9976738d",
   "metadata": {},
   "source": [
    "## Image Preprocessing Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf6f5a99-b3ec-4860-bc0e-501765bd6a6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save preprocessed images\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(DOCS_PATH):\n",
    "    for i, filename in enumerate(filenames):\n",
    "        if filename.replace('.jpg', '.json') not in os.listdir(IMAGES_OCR_PATH):\n",
    "            continue\n",
    "        image_path = os.path.join(dirpath, filename)\n",
    "        image_ocr_path = os.path.join(IMAGES_OCR_PATH, filename.replace('.jpg', '.json'))\n",
    "        img_pp = preprocess_image(image_path, image_ocr_path)\n",
    "        img_pp_bgr = cv2.cvtColor(img_pp, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(os.path.join(DOCS_PREPROCESSED_PATH, filename), img_pp_bgr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747aada0-db5e-4085-9979-e5844fc0b702",
   "metadata": {},
   "source": [
    "# Calculate embeddings code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9655b29",
   "metadata": {},
   "source": [
    "Using, the model and the preprocessed images, the embedding representation of the images will be calculated.\n",
    "<br>\n",
    "It will be necessary to set a BATCH_SIZE, this is the number of images that will be processed at the same time, the bigger, the faster. This value will be conditioned by the machine resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4393b141-b0da-4278-ab53-e0e928e635a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e65ffa2-261c-4cd6-a750-55b4546b71cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1/255.)\n",
    "def preprocess_image_with_datagen(datagen, image_path, img_size=IMG_SIZE):\n",
    "    img = load_img(image_path, target_size=(img_size, img_size))\n",
    "    img = img_to_array(img)\n",
    "    img = datagen.standardize(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c92058e-0c3a-4105-8da4-1766fcbb5c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_embeddings_batch(model, datagen, batch_filenames, img_size=IMG_SIZE):\n",
    "    imgs = [preprocess_image_with_datagen(datagen, image_path, img_size) for image_path in batch_filenames]\n",
    "    imgs_array = np.stack(imgs)\n",
    "    embeddings = model.predict(imgs_array, batch_size=len(batch_filenames))\n",
    "    return embeddings\n",
    "    \n",
    "def get_all_embeddings(folder_path, filter_doc_names=[], batch_size=BATCH_SIZE):\n",
    "    all_embeddings = {}\n",
    "    batch = []\n",
    "    batch_filenames = []\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        if filter_doc_names: \n",
    "            filenames_list = [f for f in filenames if f in filter_doc_names]\n",
    "        else:\n",
    "            filenames_list = filenames\n",
    "        for filename in filenames_list:\n",
    "            batch.append(filename)\n",
    "            batch_filenames.append(os.path.join(dirpath, filename))\n",
    "            if len(batch) == batch_size:\n",
    "                embeddings = get_doc_embeddings_batch(image_embeddings_model, datagen, batch_filenames)\n",
    "                all_embeddings.update({filename: emb for filename, emb in zip(batch, embeddings)})\n",
    "                batch = []  \n",
    "                batch_filenames = [] \n",
    "        if batch:\n",
    "            embeddings = get_doc_embeddings_batch(image_embeddings_model, datagen, batch_filenames)\n",
    "            all_embeddings.update({filename: emb for filename, emb in zip(batch, embeddings)})\n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc6a72c-90ab-4abb-859c-3cb9c47d9f83",
   "metadata": {},
   "source": [
    "# Classify documents from templates base documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5317fda",
   "metadata": {},
   "source": [
    "During this testing, we will use a set of documents categorized by template, referred to as \"base documents.\" We will then measure the similarity between each uncategorized document and the base documents. Each uncategorized document will be assigned the template of the closest matching base document. These classified documents will be stored in STORE_CLASSIFICATION_PATH. If no base document has a similarity score above the defined THRESHOLD, the document will be classified as \"Others.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9014afbe-d93c-4c89-97db-85dc1cf69192",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DOCS_TEMPLATES_PATH = '/home/dut-ftp-user/Documents/miguel/JupyterWorkspace/Similarity Classifier Siamese Network/EOB Templates/'\n",
    "BASE_DOCS_PREPROCESSED_PATH = '/home/dut-ftp-user/Documents/miguel/JupyterWorkspace/Similarity Classifier Siamese Network/All EOB/preprocessed_images/'\n",
    "UNCATEGORIZED_DOCS_PATH = '/home/dut-ftp-user/Documents/miguel/JupyterWorkspace/Similarity Classifier Siamese Network/All EOB/images/'\n",
    "UNCATEGORIZED_DOCS_PREPROCESSED_PATH = '/home/dut-ftp-user/Documents/miguel/JupyterWorkspace/Similarity Classifier Siamese Network/All EOB/preprocessed_images/'\n",
    "STORE_CLASSIFICATION_PATH = '/home/dut-ftp-user/Documents/miguel/JupyterWorkspace/Similarity Classifier Siamese Network/All EOB/classification/'\n",
    "THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c54cca76-011b-46cb-ab21-d37e2fa6d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_template_mapping_by_doc(data_path):\n",
    "    template_mapping = {}\n",
    "    for dirpath, dirnames, filenames in os.walk(data_path):\n",
    "        for filename in filenames:\n",
    "            template_mapping[filename] = os.path.basename(dirpath)\n",
    "    return template_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68835451-0d22-47de-96bf-3a5d6b677447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_docs(base_docs_embeddings, uncategorized_docs_embeddings, template_mapping, threshold=THRESHOLD):\n",
    "    base_docs_embs = np.array([emb.flatten() for emb in base_docs_embeddings.values()])\n",
    "    base_doc_names = list(base_docs_embeddings.keys())\n",
    "    uncategorized_docs_embs = np.array([emb.flatten() for emb in uncategorized_docs_embeddings.values()]) \n",
    "    uncategorized_doc_names = list(uncategorized_docs_embeddings.keys())\n",
    "    distances = cdist(base_docs_embs, uncategorized_docs_embs, metric=\"euclidean\")\n",
    "    # print(distances)\n",
    "    docs_classification = {}\n",
    "    for i in range(len(uncategorized_doc_names)):\n",
    "        uncategorized_doc_name = uncategorized_doc_names[i]\n",
    "        closest_template = 'Others'\n",
    "        min_distance = np.min(distances[:, i])\n",
    "        min_distance_index = np.argmin(distances[:, i])\n",
    "        # print(min_distance_index)\n",
    "        if min_distance < threshold:\n",
    "            closest_template = template_mapping[base_doc_names[min_distance_index]]\n",
    "        docs_classification[uncategorized_doc_name] = {'closest_template': closest_template, 'distance': round(float(min_distance), 2)}\n",
    "        \n",
    "    return docs_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51a40c41-6a1a-41cd-bf1c-493c1926ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_classified_docs(data_path, store_path, docs_classification):\n",
    "    for doc_name, classification in docs_classification.items():\n",
    "        if not os.path.exists(os.path.join(store_path, classification['closest_template'])):\n",
    "            os.mkdir(os.path.join(store_path, classification['closest_template']))\n",
    "            \n",
    "        os.system(f'cp \"{os.path.join(data_path, doc_name)}\" \"{os.path.join(store_path, classification[\"closest_template\"], doc_name)}\"')\n",
    "        # print(f'cp \"{os.path.join(data_path, doc_name)}\" \"{os.path.join(store_path, classification[\"closest_template\"], doc_name)}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "982920d1-4eb6-421b-b32a-b8d1ba936a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_docs_names = []\n",
    "for dirpath, dirnames, filenames in os.walk(BASE_DOCS_TEMPLATES_PATH):\n",
    "    base_docs_names.extend(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa738546-76c4-42c9-a938-c8b4cc3ae6ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "base_docs_embeddings = get_all_embeddings(BASE_DOCS_PREPROCESSED_PATH, batch_size=BATCH_SIZE, filter_doc_names=base_docs_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1736079-1875-4723-b71c-a792081b3d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete documents already in templates\n",
    "uncategorized_doc_names = [doc_name for doc_name in os.listdir(UNCATEGORIZED_DOCS_PATH) if doc_name not in base_docs_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31cdfbef-2c2f-43ef-bfde-4ea031884c99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step\n"
     ]
    }
   ],
   "source": [
    "uncategorized_docs_embeddings = get_all_embeddings(UNCATEGORIZED_DOCS_PREPROCESSED_PATH, batch_size=BATCH_SIZE, filter_doc_names=uncategorized_doc_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a73f1ead-293a-4319-a57a-8b2dd1f8317a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "template_mapping = get_template_mapping_by_doc(BASE_DOCS_TEMPLATES_PATH)\n",
    "docs_classification = classify_docs(base_docs_embeddings, uncategorized_docs_embeddings, template_mapping)\n",
    "save_classified_docs(UNCATEGORIZED_DOCS_PATH, STORE_CLASSIFICATION_PATH, docs_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1742da55-77df-432d-8821-f04c3d949629",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b8968",
   "metadata": {},
   "source": [
    "In this testing exercice, given a set of uncategorized documents, we will compare each of the documents and group them if they have a distance lower than THRESHOLD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "469c2bd5-16f4-43c3-bf67-7fc1f1606269",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25ae966d-f570-4a1f-a276-57f7b4fbb01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_distances(embeddings):\n",
    "    embeddings_array = np.array([emb.flatten() for emb in embeddings.values()])\n",
    "    distances = cdist(embeddings_array, embeddings_array, metric=\"euclidean\")\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb6b796d-dc3d-465a-a720-4bb86ab3386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_clustering(embeddings, threshold=THRESHOLD):\n",
    "    doc_names = list(embeddings.keys())\n",
    "    distances = get_all_distances(embeddings)\n",
    "\n",
    "    clusters = []\n",
    "    for i, doc_name in enumerate(doc_names):\n",
    "        clusters.append([doc_names[j] for j in np.where(distances[i] < threshold)[0]])\n",
    "\n",
    "    final_clusters = []\n",
    "    while clusters:\n",
    "        joined_clusters = clusters.pop(0)\n",
    "        j = 0\n",
    "        while j < len(clusters):\n",
    "            cluster2 = clusters[j]\n",
    "            if len(joined_clusters + cluster2) != len(set(joined_clusters + cluster2)): # If they have documents in common \n",
    "                joined_clusters = list(set(joined_clusters + cluster2))\n",
    "                clusters.pop(j)\n",
    "                j = 0\n",
    "            else:\n",
    "                j += 1\n",
    "        final_clusters.append(joined_clusters)\n",
    "\n",
    "    print(len(final_clusters))\n",
    "    \n",
    "    clustering_result = {}\n",
    "    for i, cluster in enumerate(final_clusters):\n",
    "        for doc_name in cluster:\n",
    "            clustering_result[doc_name] = i\n",
    "        \n",
    "    return clustering_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "264acc12-12cc-4a26-9b44-64fda83a08c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clutering_folders(data_path, store_path, clustering_result):\n",
    "    for dirpath, dirnames, filenames in os.walk(data_path):\n",
    "        for filename in filenames:\n",
    "            if filename in clustering_result:\n",
    "                cluster_n = clustering_result[filename]\n",
    "                cluster_storage_path = os.path.join(store_path, f'{os.path.basename(store_path)}_{cluster_n}')\n",
    "                if not os.path.exists(cluster_storage_path):\n",
    "                    os.mkdir(cluster_storage_path)\n",
    "                os.system(f'cp \"{os.path.join(dirpath, filename)}\" \"{os.path.join(cluster_storage_path, filename)}\"')\n",
    "            else:\n",
    "                print('Document ', filename, ' not in clustering results')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81117393-f176-4e29-9997-e737bf0bf118",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step\n"
     ]
    }
   ],
   "source": [
    "data_path = '/home/dut-ftp-user/Documents/miguel/JupyterWorkspace/Similarity Classifier Siamese Network/EOB 2024-10-15/images/'\n",
    "preprocessed_data_path = '/home/dut-ftp-user/Documents/miguel/JupyterWorkspace/Similarity Classifier Siamese Network/EOB 2024-10-15/preprocessed_images/'\n",
    "store_path = '/home/dut-ftp-user/Documents/miguel/JupyterWorkspace/Similarity Classifier Siamese Network/EOB 2024-10-15/clustering'\n",
    "embeddings = get_all_embeddings(preprocessed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "956d0b49-d0e0-48a6-b0ca-a43b3b43fb31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362\n"
     ]
    }
   ],
   "source": [
    "clustering_result = template_clustering(embeddings, threshold=THRESHOLD)\n",
    "create_clutering_folders(data_path, store_path, clustering_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9b3931-6cbc-4933-b124-f468bb40676f",
   "metadata": {},
   "source": [
    "# Iterative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddfb79a",
   "metadata": {},
   "source": [
    "This is the same exercise as before but using a different approach to cluter the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0893f111-41f0-47be-a1ac-a34be345bb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_template_clustering(embeddings, initial_threshold, avg_threshold):\n",
    "    doc_names = list(embeddings.keys())\n",
    "    distances = get_all_distances(embeddings)\n",
    "\n",
    "    clusters = []\n",
    "    for i, doc_name in enumerate(doc_names):\n",
    "        clusters.append([doc_names[j] for j in np.where(distances[i] < initial_threshold)[0]])\n",
    "\n",
    "    initial_clusters = []\n",
    "    while clusters:\n",
    "        joined_clusters = clusters.pop(0)\n",
    "        j = 0\n",
    "        while j < len(clusters):\n",
    "            cluster2 = clusters[j]\n",
    "            if len(joined_clusters + cluster2) != len(set(joined_clusters + cluster2)): # If they have documents in common \n",
    "                joined_clusters = list(set(joined_clusters + cluster2))\n",
    "                clusters.pop(j)\n",
    "                j = 0\n",
    "            else:\n",
    "                j += 1\n",
    "        initial_clusters.append(joined_clusters)\n",
    "\n",
    "    avg_clusters_embeddings = {str(i): np.mean([embeddings[doc_name] for doc_name in cluster], axis=0) for i, cluster in enumerate(initial_clusters)}\n",
    "    avg_distances = get_all_distances(avg_clusters_embeddings)\n",
    "    averaged_clusters = []\n",
    "    for i in range(avg_distances.shape[0]):\n",
    "        c = [initial_clusters[j] for j in np.where(avg_distances[i] < avg_threshold)[0]]\n",
    "        averaged_clusters.append([item for sublist in c for item in sublist])\n",
    "\n",
    "\n",
    "    final_clusters = []\n",
    "    while averaged_clusters:\n",
    "        joined_clusters = averaged_clusters.pop(0)\n",
    "        j = 0\n",
    "        while j < len(averaged_clusters):\n",
    "            cluster2 = averaged_clusters[j]\n",
    "            if len(joined_clusters + cluster2) != len(set(joined_clusters + cluster2)): # If they have documents in common \n",
    "                joined_clusters = list(set(joined_clusters + cluster2))\n",
    "                averaged_clusters.pop(j)\n",
    "                j = 0\n",
    "            else:\n",
    "                j += 1\n",
    "        final_clusters.append(joined_clusters)\n",
    "    \n",
    "    clustering_result = {}\n",
    "    for i, cluster in enumerate(final_clusters): \n",
    "        for doc_name in cluster:\n",
    "            clustering_result[doc_name] = i\n",
    "        \n",
    "    return clustering_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5abdbc99-d49b-48da-9791-069b6dbaf994",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step\n"
     ]
    }
   ],
   "source": [
    "data_path = '/home/165252@USTDEV.COM/Documents/Documents Datasets/Navistar/original_feb_21/JPGs'\n",
    "preprocessed_data_path = '/home/165252@USTDEV.COM/Documents/Documents Datasets/Navistar/original_feb_21/preprocessed_images'\n",
    "store_path = '/home/165252@USTDEV.COM/Documents/Template Identification/Test/Test1 - Navistar Feb/iterative_classified'\n",
    "embeddings = get_all_embeddings(preprocessed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8ebde428-16e9-4ab7-9686-342550b0c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_result = iterative_template_clustering(embeddings, initial_threshold=0.3, avg_threshold=0.5)\n",
    "create_clutering_folders(data_path, store_path, clustering_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa3855-7a19-4a8e-88b3-9acba379d589",
   "metadata": {},
   "source": [
    "# compare 2 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6f6b5d29-141a-4caf-9c12-5c89a0b6bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1/255.)\n",
    "def preprocess_image_with_datagen(datagen, image_path, img_size=IMG_SIZE):\n",
    "    img = load_img(image_path, target_size=(img_size, img_size))\n",
    "    img = img_to_array(img)\n",
    "    img = datagen.standardize(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e828b5a4-0118-41fe-8055-80dbfe266e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_of_2_images(model, datagen, image1_path, image2_path):\n",
    "    img1 = preprocess_image_with_datagen(datagen, image1_path, img_size=IMG_SIZE)\n",
    "    img2 = preprocess_image_with_datagen(datagen, image2_path, img_size=IMG_SIZE)\n",
    "    emb1 = model.predict(np.expand_dims(img1,axis=0))\n",
    "    emb2 = model.predict(np.expand_dims(img2,axis=0))\n",
    "    return L2(emb1,emb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9fdf2a96-d75e-45aa-995c-a44dc2c18475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7040956]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1_path = '/home/dut-ftp-user/Documents/miguel/JupyterWorkspace/Similarity Classifier Siamese Network/EOB 2024-10-15/preprocessed_images/23657_20240913_99995270_page_1.jpg'\n",
    "image2_path = '/home/dut-ftp-user/Documents/miguel/JupyterWorkspace/Similarity Classifier Siamese Network/EOB 2024-10-15/preprocessed_images/23847_20240917_99995270_page_1.jpg'\n",
    "get_distance_of_2_images(image_embeddings_model, datagen, image1_path, image2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814592f2-eca6-4bff-9219-79fa71044678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
